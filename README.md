# scraping_python

[![Python](https://img.shields.io/badge/Python-3.11%2B-blue)](https://www.python.org/)
[![Selenium](https://img.shields.io/badge/Selenium-4.0%2B-yellow)](https://www.selenium.dev/)
[![BeautifulSoup](https://img.shields.io/badge/BeautifulSoup-4.11.1-green)](https://www.crummy.com/software/BeautifulSoup/)
[![Pandas](https://img.shields.io/badge/Pandas-2.0.3-blue)](https://pandas.pydata.org/)
[![Openpyxl](https://img.shields.io/badge/Openpyxl-3.1.2-blue)](https://openpyxl.readthedocs.io/en/stable/)
[![Undetected Chromedriver](https://img.shields.io/badge/Undetected%20Chromedriver-3.3.0-orange)](https://github.com/ultrafunkamsterdam/undetected-chromedriver)
[![Webdriver Manager](https://img.shields.io/badge/Webdriver%20Manager-3.8.6-red)](https://github.com/SergeyPirogov/webdriver_manager)



- Descargar de la pagina web del supermercado todos los articulos de la seccion de almacen, tantos sus precios como las ofertas por articulos

# Proyecto de Scraping en Supermercado

Este proyecto demuestra c√≥mo realizar scraping en una p√°gina web de un supermercado para extraer informaci√≥n sobre productos. Los datos extra√≠dos incluyen nombres de productos, precios y ofertas, y se guardan en archivos separados por categor√≠a.

## Objetivo

El objetivo principal del proyecto es:

- Realizar scraping en la p√°gina de un supermercado para obtener datos de productos.
- Extraer informaci√≥n relevante, como nombres de productos, precios y ofertas.
- Organizar los datos en archivos Excel por categor√≠a para an√°lisis posterior.

## Funcionalidades

- **Extracci√≥n de Datos**: Extrae nombres, precios y ofertas de productos de una p√°gina web din√°mica.
- **Manejo de Contenido Din√°mico**: Utiliza t√©cnicas para interactuar con botones de "Mostrar m√°s" y desplazar la p√°gina para cargar todo el contenido.
- **Almacenamiento**: Guarda los datos en archivos Excel separados por categor√≠a.

## Tecnolog√≠as Utilizadas

- **Selenium**: Para automatizar la navegaci√≥n y el scraping de la p√°gina web.
- **BeautifulSoup**: Para analizar el contenido HTML y extraer la informaci√≥n necesaria.
- **Pandas**: Para manejar y guardar los datos en archivos Excel.
- **undetected_chromedriver**: Para evitar la detecci√≥n de automatizaci√≥n por parte del navegador.

## Instalaci√≥n

Para ejecutar este proyecto, necesitas tener Python y las siguientes librer√≠as instaladas:

- `selenium`
- `beautifulsoup4`
- `pandas`
- `openpyxl`
- `undetected_chromedriver`
- `webdriver_manager`

Puedes instalar las librer√≠as necesarias con el siguiente comando:




## ¬°Contribuciones Bienvenidas!

Las contribuciones son lo que hacen que la comunidad de c√≥digo abierto sea un lugar incre√≠ble para aprender, inspirar y crear. ¬°Cualquier contribuci√≥n que realices es muy apreciada!

Si tienes una sugerencia que pueda mejorar esto, por favor haz un fork del repositorio y crea un pull request. Tambi√©n puedes simplemente abrir un issue con la etiqueta "mejora". ¬°No olvides darle una estrella al proyecto! ¬°Gracias de nuevo por tu inter√©s y apoyo!

### ¬øC√≥mo Contribuir?

1. Haz un Fork del Proyecto
2. Crea tu Rama de Caracter√≠stica (`git checkout -b feature/1-caracteristica`)
3. Haz tus Cambios (`git commit -m 'A√±adir una nueva Caracter√≠stica'`)
4. Haz Push a la Rama (`git push origin feature/Caracteristica`)
5. Abre un Pull Request

## Contacto

- Jos√© F. Ramos: joseph0001@gmail.com
- Enlace del Proyecto https://github.com/JRamos84/scraping_python

Si tienes preguntas, comentarios o sugerencias, no dudes en contactarme. Estoy aqu√≠ para ayudar y colaborar contigo en cualquier cosa que necesites. ¬°Espero saber de ti pronto! üòä

```bash
pip install selenium beautifulsoup4 pandas openpyxl undetected_chromedriver webdriver_manager

